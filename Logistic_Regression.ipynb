{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Implementation of Logistic Regression**\n",
    "In this Python Notebook the implememtation of logistic regression is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.623660</td>\n",
       "      <td>78.024693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.286711</td>\n",
       "      <td>43.894998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.847409</td>\n",
       "      <td>72.902198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.182599</td>\n",
       "      <td>86.308552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.032736</td>\n",
       "      <td>75.344376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>83.489163</td>\n",
       "      <td>48.380286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>42.261701</td>\n",
       "      <td>87.103851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>99.315009</td>\n",
       "      <td>68.775409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>55.340018</td>\n",
       "      <td>64.931938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>74.775893</td>\n",
       "      <td>89.529813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1         x2  y\n",
       "0   34.623660  78.024693  0\n",
       "1   30.286711  43.894998  0\n",
       "2   35.847409  72.902198  0\n",
       "3   60.182599  86.308552  1\n",
       "4   79.032736  75.344376  1\n",
       "..        ...        ... ..\n",
       "95  83.489163  48.380286  1\n",
       "96  42.261701  87.103851  1\n",
       "97  99.315009  68.775409  1\n",
       "98  55.340018  64.931938  1\n",
       "99  74.775893  89.529813  1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"data/ex2data1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "    X = data[:,:2]\n",
    "    y = data[:,2]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data(\"data/ex2data1.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid activation function for a given input.\n",
    "\n",
    "    Parameters:\n",
    "    z (float or numpy.ndarray): The input value or array.\n",
    "\n",
    "    Returns:\n",
    "    float or numpy.ndarray: The sigmoid of the input value or each element of the input array.\n",
    "    \"\"\"\n",
    "\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_cost(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Compute the logistic regression cost function for given parameters.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Input feature matrix with shape (m, n), where m is the number of samples and n is the number of features.\n",
    "    y (numpy.ndarray): Binary labels with shape (m,), where m is the number of samples.\n",
    "    w (numpy.ndarray): Weight vector with shape (n,).\n",
    "    b (float): Bias term.\n",
    "\n",
    "    Returns:\n",
    "    float: The computed cost value based on the logistic regression model's predictions and the provided parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    m, n = X.shape\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb_i = sigmoid(np.dot(X[i], w) + b)\n",
    "        total_cost += y[i] * np.log(f_wb_i) + (1 - y[i]) * np.log(1 - f_wb_i)\n",
    "\n",
    "    total_cost = -total_cost / m\n",
    "    return total_cost\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_reg(X, y, w, b, lambda_=1):\n",
    "    \"\"\"\n",
    "    Calculate the regularized logistic regression cost function with L2 regularization.\n",
    "\n",
    "    This function computes the regularized logistic regression cost based on the provided input features, binary labels,\n",
    "    weights, bias, and L2 regularization parameter.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Input feature matrix with shape (m, n), where m is the number of samples and n is the number of features.\n",
    "    y (numpy.ndarray): Binary labels with shape (m,), where m is the number of samples.\n",
    "    w (numpy.ndarray): Weight vector with shape (n,).\n",
    "    b (float): Bias term.\n",
    "    lambda_ (float, optional): Regularization parameter. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    float: The computed regularized logistic regression cost value.\n",
    "    \"\"\"\n",
    "\n",
    "    m, n = X.shape\n",
    "    \n",
    "    # Calculate the cost without regularization using the provided function\n",
    "    cost_without_reg = compute_cost(X, y, w, b)\n",
    "    \n",
    "    # Calculate the sum of squared weights for regularization\n",
    "    reg_cost = 0\n",
    "    for i in range(n):\n",
    "        reg_cost += w[i] ** 2\n",
    "    \n",
    "    # Apply L2 regularization term\n",
    "    reg_cost = (lambda_ * reg_cost) / (2 * m)\n",
    "    \n",
    "    # Combine the original cost and the regularization term\n",
    "    total_cost = cost_without_reg + reg_cost\n",
    "    return total_cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Compute the gradient of the logistic regression cost function with respect to the weights and bias.\n",
    "\n",
    "    This function calculates the gradient of the logistic regression cost function with respect to the weights\n",
    "    and bias terms. It is used in the gradient descent optimization algorithm to update the parameters.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Input feature matrix with shape (m, n), where m is the number of samples and n is the number of features.\n",
    "    y (numpy.ndarray): Binary labels with shape (m,), where m is the number of samples.\n",
    "    w (numpy.ndarray): Weight vector with shape (n,).\n",
    "    b (float): Bias term.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray, float: The gradient of the cost function with respect to weights (dj_dw) and bias (dj_db).\n",
    "    \"\"\"\n",
    "\n",
    "    m, n = X.shape\n",
    "    dj_dw = np.zeros(w.shape)\n",
    "    dj_db = 0.0\n",
    "    \n",
    "    for i in range(m):\n",
    "        f_wb_i = sigmoid(np.dot(X[i], w) + b)\n",
    "        err_i = f_wb_i - y[i]\n",
    "        \n",
    "        for j in range(n):\n",
    "            dj_dw[j] = dj_dw[j] + err_i * X[i, j]\n",
    "        dj_db = dj_db + err_i\n",
    "    \n",
    "    dj_dw = dj_dw / m                                   \n",
    "    dj_db = dj_db / m \n",
    "    \n",
    "    return dj_dw, dj_db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With regularizarion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_reg(X, y, w, b, lambda_):\n",
    "    \"\"\"\n",
    "    Compute the gradient of the regularized logistic regression cost function with respect to the weights and bias.\n",
    "\n",
    "    This function calculates the gradient of the regularized logistic regression cost function with respect to the weights\n",
    "    and bias terms. L2 regularization is applied to the gradient of the weights.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Input feature matrix with shape (m, n), where m is the number of samples and n is the number of features.\n",
    "    y (numpy.ndarray): Binary labels with shape (m,), where m is the number of samples.\n",
    "    w (numpy.ndarray): Weight vector with shape (n,).\n",
    "    b (float): Bias term.\n",
    "    lambda_ (float): Regularization parameter.\n",
    "\n",
    "    Returns:\n",
    "    float, numpy.ndarray: The gradient of the cost function with respect to bias (dj_db) and weights (dj_dw).\n",
    "    \"\"\"\n",
    "\n",
    "    dj_dw, dj_db = compute_gradient(X, y, w, b)\n",
    "    m, n = X.shape\n",
    "    \n",
    "    for j in range(n):\n",
    "        dj_dw[j] = dj_dw[j] + (lambda_ / m) * w[j]\n",
    "    \n",
    "    return dj_db, dj_dw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descnet(X,y,w_in,b_in,alpha,num_iters):\n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn w and b. Updates w and b by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))   : Data, m examples with n features\n",
    "      y (ndarray (m,))    : target values\n",
    "      w_in (ndarray (n,)) : initial model parameters  \n",
    "      b_in (scalar)       : initial model parameter\n",
    "      cost_function       : function to compute cost\n",
    "      gradient_function   : function to compute the gradient\n",
    "      alpha (float)       : Learning rate\n",
    "      num_iters (int)     : number of iterations to run gradient descent\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,)) : Updated values of parameters \n",
    "      b (scalar)       : Updated value of parameter \n",
    "      \"\"\"\n",
    "      \n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db, dj_dw = compute_gradient_logistic(X, y, w, b)   \n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw               \n",
    "        b = b - alpha * dj_db               \n",
    "      \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( compute_cost_logistic(X, y, w, b) )\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J_history[-1]}   \")\n",
    "        \n",
    "    return w, b, J_history         #return final w,b and J history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
